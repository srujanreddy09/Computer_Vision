{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical, multi_gpu_model\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1']\n"
     ]
    }
   ],
   "source": [
    "keras.backend.set_image_data_format('channels_last')\n",
    "print(keras.backend.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "nb_epochs = 100\n",
    "batch_size = 64\n",
    "img_len = 32\n",
    "img_width = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test, num_classes=nb_classes)\n",
    "y_train = to_categorical(y_train, num_classes=nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "train_gen = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "validation_gen = datagen.flow(x_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_steps_per_epoch = int(x_train.shape[0]/batch_size)\n",
    "val_steps_per_epoch = int(x_test.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convolutional Model\n",
    "model = Sequential()\n",
    "\n",
    "#1st Convolution\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", padding = \"same\", kernel_initializer= \"he_uniform\", input_shape = (img_len, img_width, channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", padding = \"same\",kernel_initializer= \"he_uniform\"))\n",
    "model.add((BatchNormalization()))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd Convolution\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding = \"same\", kernel_initializer= \"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding = \"same\", kernel_initializer= \"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#3rd Convolution\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding = \"same\", kernel_initializer= \"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding = \"same\", kernel_initializer= \"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#DNN\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(nb_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 552,874\n",
      "Trainable params: 551,722\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Callbacks\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", patience=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Optimizer\n",
    "opt = SGD(lr = 0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Compile the model\n",
    "parallel_model = multi_gpu_model(model, gpus=2)\n",
    "parallel_model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 970s 1s/step - loss: 1.9377 - acc: 0.3378 - val_loss: 1.6330 - val_acc: 0.4323\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 1.5565 - acc: 0.4421 - val_loss: 1.4012 - val_acc: 0.4963\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 1.4386 - acc: 0.4819 - val_loss: 1.3643 - val_acc: 0.5063\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 1.3518 - acc: 0.5149 - val_loss: 1.2833 - val_acc: 0.5381\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 1.2794 - acc: 0.5416 - val_loss: 1.2548 - val_acc: 0.5539\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 1.2226 - acc: 0.5631 - val_loss: 1.2212 - val_acc: 0.5601\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 1.1676 - acc: 0.5824 - val_loss: 1.0805 - val_acc: 0.6145\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 1.1281 - acc: 0.5976 - val_loss: 1.2850 - val_acc: 0.5456\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 1.0909 - acc: 0.6086 - val_loss: 1.0970 - val_acc: 0.6124\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 1.0548 - acc: 0.6250 - val_loss: 1.0490 - val_acc: 0.6280\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 1.0264 - acc: 0.6364 - val_loss: 0.9775 - val_acc: 0.6465\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 1.0040 - acc: 0.6452 - val_loss: 0.9526 - val_acc: 0.6616\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.9805 - acc: 0.6523 - val_loss: 0.9599 - val_acc: 0.6493\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.9589 - acc: 0.6630 - val_loss: 0.9511 - val_acc: 0.6662\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.9444 - acc: 0.6677 - val_loss: 0.8973 - val_acc: 0.6824\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.9292 - acc: 0.6708 - val_loss: 0.8397 - val_acc: 0.7031\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.9027 - acc: 0.6825 - val_loss: 0.8191 - val_acc: 0.7139\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.8951 - acc: 0.6844 - val_loss: 0.8455 - val_acc: 0.6981\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8769 - acc: 0.6939 - val_loss: 0.8099 - val_acc: 0.7157\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8669 - acc: 0.6964 - val_loss: 0.8585 - val_acc: 0.6956\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8531 - acc: 0.6997 - val_loss: 0.8149 - val_acc: 0.7101\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8375 - acc: 0.7067 - val_loss: 0.7664 - val_acc: 0.7300\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8305 - acc: 0.7083 - val_loss: 0.7992 - val_acc: 0.7165\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8197 - acc: 0.7099 - val_loss: 0.8362 - val_acc: 0.7090\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.8075 - acc: 0.7159 - val_loss: 0.7386 - val_acc: 0.7318\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7986 - acc: 0.7190 - val_loss: 0.7740 - val_acc: 0.7291\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7939 - acc: 0.7224 - val_loss: 0.7268 - val_acc: 0.7455\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7845 - acc: 0.7253 - val_loss: 0.7406 - val_acc: 0.7389\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.7733 - acc: 0.7296 - val_loss: 0.7279 - val_acc: 0.7469\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7724 - acc: 0.7301 - val_loss: 0.7366 - val_acc: 0.7383\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7568 - acc: 0.7351 - val_loss: 0.7095 - val_acc: 0.7544\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7531 - acc: 0.7374 - val_loss: 0.7185 - val_acc: 0.7487\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.7396 - acc: 0.7404 - val_loss: 0.7436 - val_acc: 0.7368\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7339 - acc: 0.7421 - val_loss: 0.6780 - val_acc: 0.7618\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7223 - acc: 0.7477 - val_loss: 0.6814 - val_acc: 0.7650\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7161 - acc: 0.7495 - val_loss: 0.6911 - val_acc: 0.7561\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7104 - acc: 0.7530 - val_loss: 0.6647 - val_acc: 0.7634\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.7119 - acc: 0.7536 - val_loss: 0.6592 - val_acc: 0.7701\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6994 - acc: 0.7566 - val_loss: 0.6323 - val_acc: 0.7796\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.6981 - acc: 0.7574 - val_loss: 0.6545 - val_acc: 0.7687\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.6857 - acc: 0.7606 - val_loss: 0.6508 - val_acc: 0.7717\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.6835 - acc: 0.7616 - val_loss: 0.7011 - val_acc: 0.7539\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.6778 - acc: 0.7642 - val_loss: 0.6658 - val_acc: 0.7685\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.6734 - acc: 0.7654 - val_loss: 0.6411 - val_acc: 0.7740\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.6669 - acc: 0.7681 - val_loss: 0.6048 - val_acc: 0.7885\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.6625 - acc: 0.7689 - val_loss: 0.6149 - val_acc: 0.7851\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.6593 - acc: 0.7714 - val_loss: 0.6029 - val_acc: 0.7911\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.6541 - acc: 0.7723 - val_loss: 0.5876 - val_acc: 0.7974\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.6247 - acc: 0.7840 - val_loss: 0.5825 - val_acc: 0.7952\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.6172 - acc: 0.7865 - val_loss: 0.5664 - val_acc: 0.8041\n",
      "Epoch 56/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.6198 - acc: 0.7854 - val_loss: 0.5719 - val_acc: 0.8007\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6154 - acc: 0.7859 - val_loss: 0.5489 - val_acc: 0.8076\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.6109 - acc: 0.7868 - val_loss: 0.5450 - val_acc: 0.8094\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - 39s 51ms/step - loss: 0.6034 - acc: 0.7887 - val_loss: 0.5520 - val_acc: 0.8054\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5976 - acc: 0.7904 - val_loss: 0.5628 - val_acc: 0.8069\n",
      "Epoch 61/100\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5998 - acc: 0.7921 - val_loss: 0.5586 - val_acc: 0.8083\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.5895 - acc: 0.7930 - val_loss: 0.5443 - val_acc: 0.8111\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5873 - acc: 0.7965 - val_loss: 0.5480 - val_acc: 0.8127\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5810 - acc: 0.7983 - val_loss: 0.5288 - val_acc: 0.8161\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.5863 - acc: 0.7969 - val_loss: 0.5496 - val_acc: 0.8124\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5761 - acc: 0.8009 - val_loss: 0.5374 - val_acc: 0.8123\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5720 - acc: 0.8004 - val_loss: 0.5119 - val_acc: 0.8229\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5714 - acc: 0.8020 - val_loss: 0.5372 - val_acc: 0.8084\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5708 - acc: 0.8018 - val_loss: 0.5061 - val_acc: 0.8229\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5635 - acc: 0.8052 - val_loss: 0.5161 - val_acc: 0.8161\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5613 - acc: 0.8058 - val_loss: 0.5250 - val_acc: 0.8234\n",
      "Epoch 72/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5592 - acc: 0.8053 - val_loss: 0.5383 - val_acc: 0.8158\n",
      "Epoch 73/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5584 - acc: 0.8061 - val_loss: 0.5574 - val_acc: 0.8083\n",
      "Epoch 74/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5509 - acc: 0.8073 - val_loss: 0.5139 - val_acc: 0.8195\n",
      "Epoch 75/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5536 - acc: 0.8064 - val_loss: 0.5105 - val_acc: 0.8241\n",
      "Epoch 76/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5452 - acc: 0.8111 - val_loss: 0.5015 - val_acc: 0.8268\n",
      "Epoch 77/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5378 - acc: 0.8127 - val_loss: 0.5286 - val_acc: 0.8154\n",
      "Epoch 78/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5397 - acc: 0.8126 - val_loss: 0.5556 - val_acc: 0.8068\n",
      "Epoch 79/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5381 - acc: 0.8123 - val_loss: 0.5010 - val_acc: 0.8269\n",
      "Epoch 80/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5314 - acc: 0.8162 - val_loss: 0.4955 - val_acc: 0.8303\n",
      "Epoch 81/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5389 - acc: 0.8118 - val_loss: 0.4887 - val_acc: 0.8317\n",
      "Epoch 82/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5264 - acc: 0.8157 - val_loss: 0.5030 - val_acc: 0.8269\n",
      "Epoch 83/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5273 - acc: 0.8180 - val_loss: 0.4767 - val_acc: 0.8389\n",
      "Epoch 84/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5226 - acc: 0.8178 - val_loss: 0.4913 - val_acc: 0.8290\n",
      "Epoch 85/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5214 - acc: 0.8186 - val_loss: 0.5114 - val_acc: 0.8219\n",
      "Epoch 86/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5179 - acc: 0.8210 - val_loss: 0.5102 - val_acc: 0.8240\n",
      "Epoch 87/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5180 - acc: 0.8209 - val_loss: 0.4782 - val_acc: 0.8343\n",
      "Epoch 88/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5205 - acc: 0.8195 - val_loss: 0.4898 - val_acc: 0.8280\n",
      "Epoch 89/100\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5156 - acc: 0.8234 - val_loss: 0.4733 - val_acc: 0.8392\n",
      "Epoch 90/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5107 - acc: 0.8238 - val_loss: 0.4836 - val_acc: 0.8405\n",
      "Epoch 91/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5103 - acc: 0.8215 - val_loss: 0.4957 - val_acc: 0.8348\n",
      "Epoch 92/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5007 - acc: 0.8279 - val_loss: 0.4632 - val_acc: 0.8392\n",
      "Epoch 93/100\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.5001 - acc: 0.8275 - val_loss: 0.4697 - val_acc: 0.8398\n",
      "Epoch 94/100\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.5040 - acc: 0.8248 - val_loss: 0.4526 - val_acc: 0.8433\n",
      "Epoch 95/100\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4943 - acc: 0.8274 - val_loss: 0.4666 - val_acc: 0.8379\n",
      "Epoch 96/100\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4984 - acc: 0.8278 - val_loss: 0.4582 - val_acc: 0.8402\n",
      "Epoch 97/100\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4955 - acc: 0.8288 - val_loss: 0.4823 - val_acc: 0.8347\n",
      "Epoch 98/100\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4963 - acc: 0.8263 - val_loss: 0.4620 - val_acc: 0.8428\n",
      "Epoch 99/100\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4936 - acc: 0.8295 - val_loss: 0.4752 - val_acc: 0.8371\n",
      "Epoch 100/100\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4870 - acc: 0.8322 - val_loss: 0.4559 - val_acc: 0.8420\n"
     ]
    }
   ],
   "source": [
    "## Fitting the model\n",
    "history = parallel_model.fit_generator(train_gen, validation_data=validation_gen, epochs= nb_epochs, shuffle = True, steps_per_epoch= train_steps_per_epoch, validation_steps=val_steps_per_epoch, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is 84.77\n"
     ]
    }
   ],
   "source": [
    "_, acc = parallel_model.evaluate_generator(validation_gen)\n",
    "print(\"Validation accuracy is {}\".format(round(acc*100, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
